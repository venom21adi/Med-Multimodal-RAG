# Med-Multimodal-RAG

### Bridging the Clinical Modality Gap in Medical Retrieval

---

## ðŸŽ¯ The Problem: The Clinical Modality Gap

Traditional **medical RAG systems** struggle with *true diagnostic relevance*.

When querying complex conditions like:

> â€œPneumonia with Pleural Effusionâ€

standard **CLIP-based retrieval** often returns **â€œNo Findingâ€** X-rays because:

- Models prioritize **visual similarity**
- Not **clinical correctness**
- Lack **systemic patient context**

**Result â†’ Pretty images. Wrong diagnosis.**

This project fixes that.

---

## ðŸ§  The Core Idea

We build a **Multimodal Clinical Retrieval Engine** that aligns:

### 1ï¸âƒ£ Anatomical Evidence
- Chest X-rays  
- Source: **NIH Chest X-ray14**

### 2ï¸âƒ£ Systemic Evidence
- Blood lab measurements  
- Source: **Synthea synthetic EHR**
  - Leukocytes  
  - Platelets  
  - Other hematology markers  

Both modalities are embedded into a **shared clinical vector space**.

This transforms retrieval from:

**Image search â†’ Diagnostic discovery**

---

## ðŸš€ The Secret Sauce: Fused Embedding Strategy

Most RAG pipelines embed **pixels only**.  
We **anchor images in clinical truth**.

### 1ï¸âƒ£ Vector Fusion (Late Fusion)

During ingestion, we combine:

- Visual embedding from the X-ray  
- Expert-labeled clinical findings  

```
V_fused = Normalize(w1 * V_pixel + w2 * V_label)
```

### Why this matters

This **physically shifts** an image vector toward its:

- True **diagnostic neighborhood**
- Not just **visual look-alikes**

So:

- Effusion X-ray â†’ retrieved for **Effusion query**  
- Not â†’ random clean lung image

---

### 2ï¸âƒ£ Hybrid Retrieval (Anti-Modality-Drowning)

We run **dual independent searches**:

- Top **N text records**
- Top **N image records**

Then merge and rank to produce a:

## ðŸ©º Clinical Brief

Guaranteeing:

- Radiology findings **present**
- Lab abnormalities **present**
- No single modality dominates retrieval

---

## ðŸ—ï¸ Architecture

### Vector Database
- **PostgreSQL + pgvector**
- High-performance similarity search  
- Scalable and production-friendly

### Multimodal Model
- **BiomedCLIP**
  - ViT-B-16 (vision)
  - PubMedBERT (text)
- Pretrained on **biomedical corpora**

### Data Sources
- **NIH Chest X-ray14**
- **Synthea synthetic patient records**

---

## ðŸ“Š What This Enables

- Clinically meaningful **image retrieval**
- Multimodal **diagnostic context generation**
- Foundation for:
  - Clinical decision support
  - Radiology search engines
  - Medical AI copilots



## âš ï¸ Disclaimer

This project is **for research purposes only**.  
**Not approved for clinical or diagnostic use.**

---

## ðŸ”Ž Example: Hybrid Clinical Retrieval Output

Below are real outputs from the **BiomedCLIP Hybrid Multimodal Search Engine**  
demonstrating fused retrieval across **radiology images** and **laboratory data**.

---

### Query 1
**Input:**  
`Anteroposterior chest radiograph showing opacification of the costophrenic sulcus and patchy consolidations in the lower lobes`

```
ðŸ–¼ï¸ [IMAGE] (Similarity: 0.6175)
 > Chest X-ray findings: Effusion. Filename: 00001775_001.png

ðŸ“„ [TEXT] (Similarity: 0.6150)
 > Platelets: 188.4 Ã—10Â³/ÂµL (2020-01-25)

ðŸ–¼ï¸ [IMAGE] (Similarity: 0.6073)
 > No Finding. Filename: 00000099_006.png

ðŸ–¼ï¸ [IMAGE] (Similarity: 0.6060)
 > Atelectasis, Consolidation, Effusion. Filename: 00001558_005.png

ðŸ“„ [TEXT] (Similarity: 0.5995)
 > Leukocytes: 7.3 Ã—10Â³/ÂµL (2020-01-25)
```

**Clinical Brief (Auto-Generated)**

- **Laboratory Summary:** Relevant hematology markers detected  
- **Imaging Summary:** Multiple X-rays consistent with effusion and consolidation  
- **Advisor Note:** Combined lab and imaging evidence supports **pneumonia with pleural effusion**

---

### Query 2
**Input:**  
`consolidation and blunted costophrenic angles`

```
ðŸ“„ [TEXT] (Similarity: 0.6496)
 > Leukocytes: 7.3 Ã—10Â³/ÂµL

ðŸ–¼ï¸ [IMAGE] (Similarity: 0.6382)
 > Effusion. Filename: 00000061_002.png

ðŸ–¼ï¸ [IMAGE] (Similarity: 0.6200)
 > Consolidation, Effusion, Infiltration, Nodule. Filename: 00000061_025.png
```

**Clinical Interpretation**

- Imaging repeatedly retrieves **effusion-related studies**
- Lab markers remain **consistent with inflammatory process**
- Suggests **pulmonary infection with pleural involvement**

---

### Query 3
**Input:**  
`pneumonia with pleural effusion`

```
ðŸ“„ Leukocytes: 7.3 Ã—10Â³/ÂµL  (Similarity: 0.6927)
ðŸ“„ Platelets: 188.4 Ã—10Â³/ÂµL (Similarity: 0.6882)
ðŸ–¼ï¸ Effusion X-ray matches   (Similarity â‰ˆ 0.63)
```

**Result**

Clear **cross-modal agreement** between:

- Elevated inflammatory markers  
- Effusion-positive radiographs  

âž¡ï¸ Strong diagnostic clustering around **pneumonia + pleural effusion**

---

### Query 4
**Input:**  
`Patient with high Body Mass Index and respiratory issues`

```
ðŸ“„ BMI: 16.5 kg/mÂ² (Similarity: 0.7699)
ðŸ“„ Respiratory Rate: 16/min
ðŸ–¼ï¸ Consolidation / Cardiomegaly findings
```

**Observation**

- Text retrieval dominates due to **systemic query wording**
- Imaging still contributes **cardiopulmonary abnormalities**
- Demonstrates **balanced multimodal retrieval**, not image-only bias

---

## ðŸ§  Why This Matters

These examples show the system can:

- Retrieve **clinically relevant radiographs**
- Align them with **supporting laboratory evidence**
- Produce a **coherent diagnostic brief**

This validates the **Multimodal Fusion + Hybrid Retrieval** design  
as a step toward **clinically grounded medical RAG**.

---

## ðŸ“½ï¸ Demo

Hybrid multimodal retrieval across radiology + lab data:

![Demo](assets/With_HNSW_Index.gif)


## ðŸ” RAGAS-Based Reliability Audit

This project now includes a structured evaluation pipeline using **RAGAS** to audit the Medical RAG system across multiple reliability dimensions.

---

### ðŸ§  Evaluation Stack

- **Generation Model:** `mistral:7b-instruct` (Ollama)
- **Judge Model:** `mistral:7b-instruct`
- **Embedding Model (RAGAS):** `nomic-embed-text`
- **Retrieval Embeddings:** `BiomedCLIP`
- **Vector Index:** `PostgreSQL + pgvector (HNSW)`

#### Corpus Scale
- ~152,000 structured Synthea clinical records  
- ~3,500 NIH Chest X-ray studies  

---

### ðŸ“Š Metrics Evaluated

- **Faithfulness** â€” Did the LLM answer strictly use retrieved context?
- **Answer Relevancy** â€” Did the answer directly address the question?
- **Context Precision** â€” Were retrieved chunks genuinely useful?
- **Context Recall** â€” Was enough relevant evidence retrieved?

---

### ðŸ§ª Example Audit Results

#### 1ï¸âƒ£ White Blood Cell Query

| Metric              | Score |
|---------------------|-------|
| Faithfulness        | 0.750 |
| Answer Relevancy    | 0.855 |
| Context Precision   | 1.000 |
| Context Recall      | 0.000 |

---

#### 2ï¸âƒ£ Heart Rate Query

| Metric              | Score |
|---------------------|-------|
| Faithfulness        | 1.000 |
| Answer Relevancy    | 0.938 |
| Context Precision   | 1.000 |
| Context Recall      | 0.500 |

---

### ðŸ”Ž Key Insight

> High generation quality can mask retrieval coverage failure.

Even when answers appear grounded and relevant, insufficient retrieval coverage can reduce system reliability â€” especially in high-stakes domains like healthcare.

---

### ðŸ—‚ Audit Artifacts

The repository includes:

- Full RAGAS evaluation pipeline
- Structured JSON logs for reproducibility
- Detailed per-query metric breakdown
- Query rewriting layer for structured clinical alignment

---



